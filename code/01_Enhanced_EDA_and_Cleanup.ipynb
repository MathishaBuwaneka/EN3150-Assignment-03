{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# ==========================================\n",
    "# 0) Configuration\n",
    "# ==========================================\n",
    "DATASET_DIR = r\"C:\\Users\\User\\Desktop\\CNN asignment\\realwaste\\realwaste-main\\RealWaste\"\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "RANDOM_SEED = 42\n",
    "MIN_SIZE = 32\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ==========================================\n",
    "# 1) Scan and Build DataFrame\n",
    "# ==========================================\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: Scanning Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rows = []\n",
    "root = Path(DATASET_DIR)\n",
    "classes = sorted([d.name for d in root.iterdir() if d.is_dir()])\n",
    "print(f\"Found classes: {classes}\\n\")\n",
    "\n",
    "corrupt_files = []\n",
    "for cls in classes:\n",
    "    cls_path = root / cls\n",
    "    for p in cls_path.rglob(\"*\"):\n",
    "        if p.suffix.lower() in IMG_EXTS:\n",
    "            try:\n",
    "                # Verify image integrity\n",
    "                with Image.open(p) as im:\n",
    "                    im.verify()\n",
    "                # Get dimensions\n",
    "                with Image.open(p) as im:\n",
    "                    w, h = im.size\n",
    "                    mode = im.mode\n",
    "                rows.append({\n",
    "                    \"path\": str(p),\n",
    "                    \"label\": cls,\n",
    "                    \"w\": w,\n",
    "                    \"h\": h,\n",
    "                    \"mode\": mode,\n",
    "                    \"aspect_ratio\": w/h if h > 0 else 0\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Corrupt/Invalid: {p} -> {e}\")\n",
    "                corrupt_files.append(str(p))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"\\n✓ Total valid images: {len(df)}\")\n",
    "print(f\"✗ Corrupt images found: {len(corrupt_files)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2) Enhanced EDA\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Exploratory Data Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\n--- Class Distribution ---\")\n",
    "class_counts = df.groupby(\"label\").size().sort_values(ascending=False)\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_samples = class_counts.max()\n",
    "min_samples = class_counts.min()\n",
    "imbalance_ratio = max_samples / min_samples\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}x (max/min)\")\n",
    "\n",
    "# Image statistics\n",
    "print(\"\\n--- Image Statistics ---\")\n",
    "print(f\"Width  -> min: {df['w'].min()}, max: {df['w'].max()}, mean: {df['w'].mean():.1f}\")\n",
    "print(f\"Height -> min: {df['h'].min()}, max: {df['h'].max()}, mean: {df['h'].mean():.1f}\")\n",
    "print(f\"Aspect Ratio -> min: {df['aspect_ratio'].min():.2f}, max: {df['aspect_ratio'].max():.2f}\")\n",
    "\n",
    "# Color modes\n",
    "print(f\"\\n--- Color Modes ---\")\n",
    "print(df['mode'].value_counts())\n",
    "\n",
    "# ==========================================\n",
    "# 3) Comprehensive Visualizations\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Creating Visualizations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 3.1) Class distribution bar plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "class_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Number of Images', fontsize=12)\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    ax.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 3.2) Aspect ratio distribution\n",
    "ax = axes[0, 1]\n",
    "df['aspect_ratio'].clip(0, 4).hist(bins=50, ax=ax, color='coral', edgecolor='black')\n",
    "ax.set_title('Aspect Ratio Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Width / Height', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.axvline(1, color='red', linestyle='--', label='Square (1:1)')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3.3) Image size scatter\n",
    "ax = axes[1, 0]\n",
    "scatter = ax.scatter(df['w'], df['h'], c=df['label'].astype('category').cat.codes, \n",
    "                    alpha=0.6, s=10, cmap='tab10')\n",
    "ax.set_title('Image Dimensions Scatter', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Width (pixels)', fontsize=12)\n",
    "ax.set_ylabel('Height (pixels)', fontsize=12)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3.4) Box plot of dimensions by class\n",
    "ax = axes[1, 1]\n",
    "dims_by_class = []\n",
    "labels_for_box = []\n",
    "for cls in classes:\n",
    "    cls_df = df[df['label'] == cls]\n",
    "    dims_by_class.append(cls_df['w'].values)\n",
    "    labels_for_box.append(cls)\n",
    "ax.boxplot(dims_by_class, labels=labels_for_box, vert=True)\n",
    "ax.set_title('Width Distribution by Class', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Width (pixels)', fontsize=12)\n",
    "ax.set_xticklabels(labels_for_box, rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 4) Data Cleaning Pipeline\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Data Cleaning\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_count = len(df)\n",
    "\n",
    "# 4.1) Filter tiny images\n",
    "df = df[(df['w'] >= MIN_SIZE) & (df['h'] >= MIN_SIZE)].reset_index(drop=True)\n",
    "print(f\"✓ Removed tiny images (< {MIN_SIZE}px): {initial_count - len(df)}\")\n",
    "\n",
    "# 4.2) Filter extreme aspect ratios (based on paper recommendations)\n",
    "before_ar = len(df)\n",
    "df = df[(df['aspect_ratio'] > 0.2) & (df['aspect_ratio'] < 5)].reset_index(drop=True)\n",
    "print(f\"✓ Removed extreme aspect ratios: {before_ar - len(df)}\")\n",
    "\n",
    "# 4.3) Remove duplicates\n",
    "before_dup = len(df)\n",
    "df = df.drop_duplicates(subset=['path']).reset_index(drop=True)\n",
    "print(f\"✓ Removed duplicate paths: {before_dup - len(df)}\")\n",
    "\n",
    "print(f\"\\n✓ Final dataset size: {len(df)} images\")\n",
    "\n",
    "# ==========================================\n",
    "# 5) Sample Images Visualization\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: Sample Images per Class\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(len(classes), n_cols, figsize=(15, 3*len(classes)))\n",
    "if len(classes) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    cls_paths = df[df['label'] == cls]['path'].tolist()\n",
    "    sample_paths = random.sample(cls_paths, min(n_cols, len(cls_paths)))\n",
    "    \n",
    "    for j, p in enumerate(sample_paths):\n",
    "        img = Image.open(p).convert('RGB')\n",
    "        axes[i, j].imshow(img)\n",
    "        axes[i, j].axis('off')\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel(cls, fontsize=12, fontweight='bold', rotation=0, \n",
    "                                  labelpad=50, ha='right')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images_per_class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 6) Stratified Train/Val/Test Split\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: Creating Stratified Splits\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% train, 15% val, 15% test split\n",
    "# First split: 70% train, 30% temp (for val+test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, stratify=df['label'], random_state=RANDOM_SEED\n",
    ")\n",
    "# Second split: Split temp into 50-50 (15% val, 15% test of total)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df['label'], random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\n--- Class Distribution in Splits ---\")\n",
    "split_dist = pd.DataFrame({\n",
    "    'Train': train_df['label'].value_counts().sort_index(),\n",
    "    'Val': val_df['label'].value_counts().sort_index(),\n",
    "    'Test': test_df['label'].value_counts().sort_index()\n",
    "})\n",
    "print(split_dist)\n",
    "\n",
    "# ==========================================\n",
    "# 7) Save Cleaned Data\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: Saving Processed Data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df.to_csv('manifest_clean.csv', index=False)\n",
    "train_df.to_csv('train_manifest.csv', index=False)\n",
    "val_df.to_csv('val_manifest.csv', index=False)\n",
    "test_df.to_csv('test_manifest.csv', index=False)\n",
    "\n",
    "with open('classes.json', 'w') as f:\n",
    "    json.dump(classes, f, indent=2)\n",
    "\n",
    "print(\"✓ Saved manifest_clean.csv\")\n",
    "print(\"✓ Saved train_manifest.csv\")\n",
    "print(\"✓ Saved val_manifest.csv\")\n",
    "print(\"✓ Saved test_manifest.csv\")\n",
    "print(\"✓ Saved classes.json\")\n",
    "\n",
    "# ==========================================\n",
    "# 8) Generate EDA Report\n",
    "# ==========================================\n",
    "report = f\"\"\"\n",
    "{'='*60}\n",
    "REALWASTE DATASET - EDA REPORT\n",
    "{'='*60}\n",
    "\n",
    "Dataset Statistics:\n",
    "- Total Images: {len(df)}\n",
    "- Number of Classes: {len(classes)}\n",
    "- Classes: {', '.join(classes)}\n",
    "\n",
    "Class Distribution:\n",
    "{class_counts.to_string()}\n",
    "\n",
    "Imbalance Ratio: {imbalance_ratio:.2f}x\n",
    "\n",
    "Image Dimensions:\n",
    "- Width:  min={df['w'].min()}, max={df['w'].max()}, mean={df['w'].mean():.1f}\n",
    "- Height: min={df['h'].min()}, max={df['h'].max()}, mean={df['h'].mean():.1f}\n",
    "- Aspect Ratio: min={df['aspect_ratio'].min():.2f}, max={df['aspect_ratio'].max():.2f}\n",
    "\n",
    "Data Split:\n",
    "- Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\n",
    "- Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\n",
    "- Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\n",
    "\n",
    "Recommendations:\n",
    "1. Use weighted loss function due to class imbalance (ratio: {imbalance_ratio:.2f}x)\n",
    "2. Apply aggressive data augmentation (geometric + color transforms)\n",
    "3. Use larger input resolution (256x256 or 384x384) based on paper findings\n",
    "4. Consider focal loss for handling class imbalance\n",
    "5. Implement early stopping with patience based on validation performance\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "\n",
    "with open('eda_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n✓ Saved eda_report.txt\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
